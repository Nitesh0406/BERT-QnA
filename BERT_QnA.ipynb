{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Bert Implimentation for Que and Ans</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"huggingface.png\" alt=\"huggingface\" style=\"width:1000px;height:400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "* Overview\n",
    "* BERT Summary\n",
    "* BERT Tokenization\n",
    "* BERT Embaddings\n",
    "* Understand BERT Outputs\n",
    "* Embedding layer in BERT\n",
    "* BERT for QnA\n",
    "* Testing model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers) is the state of the art NLP technique released by the google AI research in october 2018. The best thing about BERT is it is open source transfer learning plateform for almost all variety of NLP problem. One of the most common usecase of BERT is question and answer problem where the model requires a passage and question and it generate answer for that question from the passage. In this blog post I will impliment BERT model for Que and Ans task.\n",
    "\n",
    "Unlike Other NLP task such as Sentiment Analysis, Part of speech tagging or Name entity recognition, BERT model does not require fine tuning for que and ans application as it gives significantly good results on pretrained model.\n",
    "\n",
    "This blog is continuation of Jay Allamar's [blog](http://jalammar.github.io/illustrated-bert/) where he explained the architecture and woking of BERT model amazingly. I will try to fill the missing dots which is not covered in that blog and I will also share some problems that I faced while implimenting this model for Que and Ans task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Summary\n",
    "If you have gone through this [blog](http://jalammar.github.io/illustrated-bert/) then you must have some idea about query , key , value, self attention , attention heads and positional encoding. Now let's directly go to the problems that you might face while implimenting BERT.\n",
    "\n",
    "In this blog we will impliment BERT for QnA task. We know that mathematical model do not accept words or sentenses so first we have to convert our sentenses into some numbers so that the model can process it. The sequence of steps is Tokenization , Token ids and Embedding vectors. \n",
    "\n",
    "### BERT Tokenization\n",
    "Tokenization is the first process where we convert a sentenses into list of words such that each word in the list can be mapped to Embadding matrix which will return 768 dimentional or 1024 dimentional vector for bert base and bert large respectively. Now what is Embadding matrix? I will show you this matrix when we load our BERT large model for QnA for now lets first understand how bert tokenizer works and how its different from other embadding techniques.\n",
    "\n",
    "The vocabulary size is 30,522 for english language and ofcourse this can not cover all english words. Then how BERT tokenizer deal with the words which is not in the vocabulary. Let's see this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can simply print tokenizer.vocab to see all 30,522 tokens and its corresponding token ids. There are some special tokens which BERT tokenizer uses for special purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(tokenizer.vocab)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}\n",
      "dict_values(['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]'])\n",
      "[100, 102, 0, 101, 103]\n"
     ]
    }
   ],
   "source": [
    "special_tokens = tokenizer.special_tokens_map\n",
    "print(special_tokens)\n",
    "special_token_ids = tokenizer.convert_tokens_to_ids(special_tokens.values())\n",
    "print(special_tokens.values())\n",
    "print(special_token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [UNK] : token_id = 100 and used for unknown or misspelled words.\n",
    "* [CLS] : token_id = 101 By defalt starting token for each input. Last hidden vector corresponding to [CLS] used for classification. We will talk about it later in this blog.\n",
    "* [SEP] : token_id = 102 used as separation taken between two sentenses. \n",
    "* [MASK]:  token_id = 103 used for masking. Masking is a technique that BERT uses while generation sequence of words, at a time it generate one word and mask all other tokens.\n",
    "* [PAD]:  token_id = 0 used to equal the lenght of sentenses in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hey', 'guys', '!', 'this', 'is', 'ni', '##tes', '##h', 'welcoming', 'you', 'into', 'my', 'blog', 'post', '.']\n",
      "[4931, 4364, 999, 2023, 2003, 9152, 4570, 2232, 18066, 2017, 2046, 2026, 9927, 2695, 1012]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize('Hey guys! This is Nitesh welcoming you into my blog post.')\n",
    "print(tokens)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ofcourse the word 'Nitesh' which is my name is not there in the vocabulary as I am not a famous personality. One thing to notice that when a word is not there in the vocabulary then the tokenizer breaks down the word into subwords like in this case 'Nitesh' --> 'ni' + '##tes' + '##h' . What are those # tags?\n",
    "\n",
    "BERT tokenizer uses two # tags to identify that the token containing # tags are not actual word rather it is extention of previous non # tag token. let's see one other eg.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dew', '##anga', '##n']\n",
      "[24903, 18222, 2078]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize('Dewangan')\n",
    "print(tokens)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here also the word 'Dewangan' which is my surname is break down into three tokens. You must be thinking that how breaking down unknown words into small token could actually works because the model generate separte hidden vector for each token. I will discuss about this topic when we will load the model. Till now we have understan d about BERT token and token ids. Now let's understand BERT Embaddings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Embaddings\n",
    "We have number of word embadding techniques such as bag of word, tfidt embadding and word2vec embadding technique. Out of those word2vec is advance word embadding technique which take care of semantic meaning of words. We will compare word2vec embadding technique with BERT Embadding and understand how geniously BERT generate word embadding by considering context word into consideration.\n",
    "\n",
    "Though the state of the art word2vec embadding technique holds semantic meaning of words but it does not take care of context word. lets understand it with an eg. The sentence 'After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.' uses the word 'bank' three times first and second 'bank' is reffering a \"finacial establishment that uses money deposited by customers for investment\" and third 'bank' is reffering river edge or river site. Word2vec embadding gives same embadding vector for all three 'bank' where BERT uses context word and will generate different embadding vector for same word 'bank'.   \n",
    "\n",
    "To know more about BERT Embadding you can visit this [blog](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens : 22\n",
      "[CLS]           101\n",
      "after         2,044\n",
      "stealing     11,065\n",
      "money         2,769\n",
      "from          2,013\n",
      "the           1,996\n",
      "bank          2,924\n",
      "vault        11,632\n",
      ",             1,010\n",
      "the           1,996\n",
      "bank          2,924\n",
      "robber       27,307\n",
      "was           2,001\n",
      "seen          2,464\n",
      "fishing       5,645\n",
      "on            2,006\n",
      "the           1,996\n",
      "mississippi   5,900\n",
      "river         2,314\n",
      "bank          2,924\n",
      ".             1,012\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
    "text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
    "       \"fishing on the Mississippi river bank.\"\n",
    "# Add the special tokens.\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# Display the words with their indeces.\n",
    "print(f'Number of tokens : {len(tokenized_text)}')\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our actual task is QnA but I want to show that embadding for all three 'bank' will be different. So for that I will use bert-base-uncased just for this purpose you don't have to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2cfeda9e0f445d874908f9ae8e2f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750adc5c2e8a47359b331cffb3838492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from all 12 layers. \n",
    "with torch.no_grad():\n",
    "\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    # Evaluating the model will return a different number of objects based on \n",
    "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "    # becase we set `output_hidden_states = True`, the third item will be the \n",
    "    # hidden states from all layers. See the documentation for more details:\n",
    "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.4964, -0.1831, -0.5231,  ..., -0.1902,  0.3738,  0.3964],\n",
       "         [-0.1323, -0.2762, -0.3495,  ..., -0.4567,  0.3786, -0.1096],\n",
       "         [-0.3626, -0.4002,  0.0676,  ..., -0.3207, -0.2709, -0.3004],\n",
       "         ...,\n",
       "         [ 0.2961, -0.2856, -0.0382,  ..., -0.6056, -0.5163,  0.2005],\n",
       "         [ 0.4878, -0.0909, -0.2358,  ..., -0.0017, -0.5945, -0.2431],\n",
       "         [-0.2517, -0.3519, -0.4688,  ...,  0.2500,  0.0336, -0.2627]]]), pooler_output=tensor([[-0.6031, -0.3342, -0.7174,  0.3347,  0.5145, -0.1722,  0.4502,  0.2768,\n",
       "         -0.3769, -0.9998, -0.3657,  0.7535,  0.9817, -0.0192,  0.7959, -0.3459,\n",
       "         -0.1338, -0.3026,  0.1097,  0.5836,  0.5736,  0.9999,  0.1798,  0.1845,\n",
       "          0.2250,  0.9109, -0.5653,  0.8616,  0.8994,  0.7423, -0.2525,  0.0394,\n",
       "         -0.9894, -0.1331, -0.7763, -0.9826,  0.2223, -0.6115,  0.1941,  0.0177,\n",
       "         -0.7634,  0.2312,  0.9999, -0.7000,  0.4623, -0.2202, -1.0000,  0.1908,\n",
       "         -0.8150,  0.6483,  0.5878,  0.8198,  0.1014,  0.3185,  0.3963, -0.3216,\n",
       "         -0.1701,  0.0588, -0.1544, -0.4987, -0.5284,  0.1228, -0.4823, -0.7788,\n",
       "          0.6954,  0.0891, -0.0855, -0.1500,  0.0390, -0.0760,  0.6154,  0.2662,\n",
       "         -0.0129, -0.7253,  0.1352,  0.2921, -0.5613,  1.0000,  0.1536, -0.9681,\n",
       "          0.7166,  0.2600,  0.4519,  0.5470, -0.2798, -1.0000,  0.3419, -0.2645,\n",
       "         -0.9863,  0.1263,  0.5249, -0.2000,  0.5980,  0.4752, -0.2355, -0.4808,\n",
       "         -0.3786, -0.7284, -0.0909,  0.0124, -0.0689, -0.2531, -0.1324, -0.2361,\n",
       "          0.1732, -0.3216, -0.0188,  0.2302, -0.3221,  0.4996,  0.4346, -0.1935,\n",
       "          0.2968, -0.9292,  0.5326, -0.3695, -0.9876, -0.4770, -0.9902,  0.6349,\n",
       "         -0.1863, -0.2612,  0.9123, -0.1930,  0.3110,  0.0803, -0.7598, -1.0000,\n",
       "          0.0292, -0.0628, -0.1086, -0.2135, -0.9671, -0.9521,  0.3334,  0.8675,\n",
       "          0.2254,  0.9995, -0.2908,  0.9420,  0.0336, -0.4542,  0.4123, -0.4455,\n",
       "          0.4558, -0.4442, -0.0685,  0.3043,  0.0575,  0.1843, -0.6577, -0.3121,\n",
       "         -0.1069, -0.7729, -0.2328,  0.9032, -0.4681, -0.5580,  0.3359, -0.1644,\n",
       "         -0.1572,  0.6441,  0.2810,  0.2651,  0.1532,  0.4485, -0.5299,  0.2616,\n",
       "         -0.7413, -0.0347,  0.2560, -0.2659, -0.6092, -0.9868, -0.2346,  0.4682,\n",
       "          0.9771,  0.5646,  0.2360,  0.4567, -0.2170,  0.1420, -0.9554,  0.9832,\n",
       "         -0.0935,  0.2621, -0.7901,  0.5758, -0.7642, -0.5362,  0.6374, -0.3891,\n",
       "         -0.6368, -0.0045, -0.2658, -0.1721, -0.7466,  0.4832, -0.3128, -0.2640,\n",
       "          0.0435,  0.8879,  0.5961,  0.2972,  0.0742,  0.3041, -0.7367, -0.2117,\n",
       "         -0.0500,  0.0825,  0.0273,  0.9870, -0.5612, -0.0353, -0.8011, -0.9833,\n",
       "         -0.1874, -0.7143,  0.0476, -0.4776,  0.4406, -0.7087, -0.3319,  0.1035,\n",
       "         -0.2959, -0.6915,  0.2840, -0.5485,  0.3292, -0.3018,  0.8687,  0.7867,\n",
       "         -0.5158, -0.2411,  0.9175, -0.7601, -0.6967, -0.0763, -0.1411,  0.6739,\n",
       "         -0.6006,  0.9645,  0.6723,  0.3451, -0.9112, -0.6897, -0.3042, -0.0059,\n",
       "         -0.0918, -0.6402,  0.5602,  0.3850,  0.2737,  0.7868, -0.4155,  0.8343,\n",
       "         -0.9288, -0.9377, -0.9803,  0.1936, -0.9873,  0.7978,  0.1702,  0.6547,\n",
       "         -0.3664, -0.3837, -0.9602,  0.2690,  0.0832,  0.8077, -0.5984, -0.5181,\n",
       "         -0.4783, -0.9236, -0.0773, -0.0542,  0.1906,  0.0659, -0.8882,  0.3529,\n",
       "          0.5142,  0.4257, -0.8504,  0.9686,  1.0000,  0.9745,  0.7975,  0.3701,\n",
       "         -0.9993, -0.9159,  0.9999, -0.9649, -1.0000, -0.8484, -0.5494,  0.2254,\n",
       "         -1.0000, -0.0892,  0.0449, -0.8989,  0.2432,  0.9673,  0.7904, -1.0000,\n",
       "          0.8539,  0.8224, -0.5027,  0.8026, -0.2741,  0.9723,  0.3954,  0.5613,\n",
       "         -0.2778,  0.4943, -0.7842, -0.5614, -0.4786, -0.7206,  0.9944, -0.0361,\n",
       "         -0.2827, -0.8623,  0.6206, -0.0204, -0.2777, -0.9243, -0.2374,  0.5576,\n",
       "          0.4833,  0.1621,  0.2181, -0.4744,  0.1432, -0.0688, -0.3646,  0.5594,\n",
       "         -0.8221, -0.1388,  0.5845, -0.0662,  0.0617, -0.9573,  0.9249, -0.4059,\n",
       "          0.5819,  1.0000,  0.8847, -0.6462,  0.4425,  0.1442,  0.2397,  1.0000,\n",
       "          0.3757, -0.9790, -0.5021,  0.5227, -0.4537, -0.4564,  0.9975, -0.1468,\n",
       "         -0.4530, -0.2211,  0.9849, -0.9892,  0.9874, -0.6354, -0.9533,  0.9617,\n",
       "          0.9100, -0.3272, -0.5809,  0.1221,  0.2137,  0.1775, -0.6459,  0.5595,\n",
       "          0.3555,  0.0030,  0.7183,  0.1490, -0.4345,  0.2424, -0.5088,  0.0014,\n",
       "          0.9025,  0.3578, -0.0445, -0.0357, -0.2723, -0.8130, -0.9344,  0.4227,\n",
       "          1.0000, -0.1721,  0.8243,  0.0665,  0.0115, -0.1497,  0.4186,  0.3168,\n",
       "         -0.3061, -0.5515,  0.7428, -0.7339, -0.9949,  0.1418,  0.0288,  0.1303,\n",
       "          0.9994,  0.6172,  0.1452,  0.4381,  0.9631, -0.0898, -0.1024,  0.3720,\n",
       "          0.9655, -0.2082,  0.4160,  0.2856, -0.4470, -0.0806, -0.5101, -0.1494,\n",
       "         -0.8861,  0.3496, -0.9617,  0.9112,  0.9032,  0.4198,  0.1110,  0.5989,\n",
       "          1.0000, -0.9781,  0.0478,  0.8043, -0.0370, -0.9994, -0.4571, -0.3764,\n",
       "         -0.0341, -0.3013,  0.0021,  0.1011, -0.9597,  0.1910,  0.7922, -0.5135,\n",
       "         -0.9862,  0.0285,  0.4023,  0.2365, -0.9728, -0.3717, -0.4726,  0.2997,\n",
       "         -0.0355, -0.9264,  0.3197, -0.3812,  0.3245, -0.1921,  0.4575,  0.3563,\n",
       "          0.9515, -0.8870, -0.3251, -0.1148, -0.6957,  0.4810, -0.2975, -0.7607,\n",
       "         -0.1648,  1.0000, -0.4754,  0.5410,  0.3828,  0.1635, -0.2463,  0.1942,\n",
       "          0.8299,  0.1894,  0.0876, -0.6173,  0.7333, -0.2475,  0.3843,  0.7312,\n",
       "         -0.0760,  0.6759,  0.7408,  0.1733,  0.0710,  0.0930,  0.9232, -0.0188,\n",
       "         -0.2704, -0.3332, -0.0659, -0.3261,  0.7431,  1.0000,  0.1622,  0.5590,\n",
       "         -0.9939, -0.7758, -0.7434,  1.0000,  0.8649, -0.6865,  0.5643,  0.4938,\n",
       "         -0.2507, -0.0745, -0.1468, -0.2566,  0.2531,  0.0162,  0.9603, -0.5751,\n",
       "         -0.9828, -0.4233,  0.3365, -0.9327,  0.9997, -0.5279, -0.2036, -0.2868,\n",
       "         -0.4147, -0.9348, -0.0477, -0.9812, -0.1836,  0.1210,  0.9609,  0.2963,\n",
       "         -0.4743, -0.7886,  0.8539,  0.4805, -0.8080, -0.9297,  0.9734, -0.8989,\n",
       "          0.3318,  1.0000,  0.4983,  0.0046,  0.1519, -0.2174,  0.3163, -0.3975,\n",
       "          0.5479, -0.9144, -0.0836, -0.1866,  0.3943, -0.1005, -0.9010,  0.5822,\n",
       "          0.0541, -0.4141, -0.4825, -0.0623,  0.3400,  0.6302, -0.1646, -0.0293,\n",
       "          0.1773,  0.0035, -0.7814, -0.2836, -0.3813, -0.9999,  0.5009, -1.0000,\n",
       "          0.6917, -0.3492, -0.2238,  0.7105,  0.8107,  0.7481, -0.4549, -0.4793,\n",
       "          0.7201,  0.6103, -0.1528, -0.2139, -0.4457,  0.2485,  0.0196,  0.1607,\n",
       "         -0.3812,  0.5145, -0.2807,  1.0000,  0.0829, -0.3200, -0.5929,  0.2053,\n",
       "         -0.2679,  1.0000, -0.2241, -0.9651,  0.1681, -0.5537, -0.5055,  0.4764,\n",
       "         -0.0439, -0.7710, -0.8442,  0.7623,  0.3223, -0.5828,  0.5065, -0.2420,\n",
       "         -0.2434, -0.0287,  0.8268,  0.9844,  0.8406,  0.3518, -0.9611, -0.3503,\n",
       "          0.9309,  0.1013, -0.1565, -0.0012,  1.0000,  0.4139, -0.7002,  0.0942,\n",
       "         -0.8437, -0.2698, -0.7333,  0.2633,  0.0600,  0.9015, -0.2510,  0.9170,\n",
       "         -0.7876, -0.0735, -0.5044,  0.2206,  0.2786, -0.8753, -0.9837, -0.9885,\n",
       "          0.5545, -0.2806, -0.0823,  0.3698,  0.1557,  0.2687,  0.4354, -1.0000,\n",
       "          0.9126,  0.3169,  0.7036,  0.9720,  0.4816,  0.6401,  0.3309, -0.9813,\n",
       "         -0.6150, -0.3007, -0.1601,  0.3913,  0.3273,  0.6264,  0.2662, -0.3612,\n",
       "         -0.6613, -0.3084, -0.9703, -0.9852,  0.3886,  0.0251, -0.3822,  0.9373,\n",
       "         -0.0961,  0.0824,  0.4406, -0.5929,  0.1701,  0.6097,  0.1687, -0.0525,\n",
       "          0.5533,  0.8141,  0.7725,  0.9789, -0.7193,  0.2995, -0.5652,  0.3757,\n",
       "          0.9063, -0.9190,  0.0740,  0.3566, -0.1535,  0.1921, -0.1948, -0.4410,\n",
       "          0.9270, -0.0852,  0.3333, -0.2275,  0.1727, -0.3694, -0.1233, -0.7592,\n",
       "         -0.5162,  0.4856, -0.1530,  0.8161,  0.7259, -0.0103, -0.4483, -0.1682,\n",
       "          0.0424, -0.8891,  0.2156, -0.0442,  0.6451,  0.3764, -0.4232,  0.9787,\n",
       "         -0.0989, -0.3853, -0.3173, -0.5348,  0.5307, -0.6883, -0.3786, -0.4665,\n",
       "          0.7207,  0.3239,  0.9999, -0.5526, -0.4825, -0.3439, -0.3580,  0.1069,\n",
       "         -0.2620, -1.0000,  0.2673, -0.3037,  0.4706, -0.6132,  0.8511, -0.4910,\n",
       "         -0.7231, -0.1092,  0.5412,  0.5265, -0.4635, -0.2461,  0.4946, -0.3469,\n",
       "          0.9149,  0.5902, -0.1862,  0.7004,  0.5465, -0.2839, -0.5723,  0.6648]]), hidden_states=(tensor([[[ 0.1686, -0.2858, -0.3261,  ..., -0.0276,  0.0383,  0.1640],\n",
       "         [ 0.2329,  0.1390,  0.2979,  ..., -0.0655,  0.8885,  0.5109],\n",
       "         [ 0.2257, -0.7165, -0.7255,  ...,  0.4844,  0.6030, -0.0957],\n",
       "         ...,\n",
       "         [-0.0374, -0.6155, -1.4419,  ...,  0.0793, -0.0811, -0.3802],\n",
       "         [-0.0228,  0.4207, -0.3288,  ...,  0.4464,  0.5178,  0.5501],\n",
       "         [-0.2350,  0.1566, -0.0462,  ..., -0.4206,  0.3074, -0.2288]]]), tensor([[[ 0.0522,  0.0595, -0.2179,  ...,  0.2280, -0.0712,  0.0148],\n",
       "         [ 0.3819,  0.1475,  0.2414,  ...,  0.3397,  0.7607,  0.4999],\n",
       "         [ 0.1705, -0.6168, -0.7296,  ...,  0.8631,  0.6274, -0.3727],\n",
       "         ...,\n",
       "         [ 0.6982, -0.4554, -1.7845,  ...,  0.3308,  0.0710, -0.5187],\n",
       "         [-0.0905,  0.1862, -0.4437,  ...,  0.2244,  0.1810,  0.3740],\n",
       "         [-0.0825,  0.0466, -0.1526,  ..., -0.2033,  0.3370, -0.1767]]]), tensor([[[-0.0357, -0.2022, -0.4103,  ...,  0.2511,  0.0586, -0.0547],\n",
       "         [ 0.1430,  0.0747,  0.0595,  ..., -0.2914,  0.1733,  0.4265],\n",
       "         [ 0.5752, -1.2385, -0.5650,  ...,  0.8995,  0.4652, -0.8080],\n",
       "         ...,\n",
       "         [ 0.9157, -0.4118, -1.6042,  ...,  0.1454,  0.1699, -0.2230],\n",
       "         [-0.1816,  0.0099,  0.0370,  ..., -0.2178,  0.0481,  0.3477],\n",
       "         [-0.1524, -0.1068, -0.0868,  ..., -0.1369,  0.2633, -0.3754]]]), tensor([[[-0.0183, -0.3853, -0.1600,  ...,  0.2446,  0.2160,  0.0633],\n",
       "         [ 0.7727, -0.3786,  0.6677,  ..., -0.2014,  0.0094,  0.6461],\n",
       "         [ 0.8822, -0.7807, -0.6305,  ...,  0.5223,  0.3687, -0.9875],\n",
       "         ...,\n",
       "         [ 0.9788, -0.0669, -1.6344,  ...,  0.0341,  0.0437, -0.1636],\n",
       "         [-0.4724, -0.0258,  0.3107,  ..., -0.2553, -0.1049,  0.0897],\n",
       "         [-0.0816, -0.1028,  0.0947,  ...,  0.0091,  0.0649, -0.0646]]]), tensor([[[ 0.0207, -0.3990, -0.8255,  ...,  0.3448,  0.0951,  0.3650],\n",
       "         [ 0.5667, -0.7513,  0.0695,  ..., -0.1052, -0.1700,  0.4333],\n",
       "         [ 0.7095, -0.2044, -0.1709,  ...,  0.7092,  0.0542, -1.0380],\n",
       "         ...,\n",
       "         [ 1.3519,  0.3352, -1.3555,  ...,  0.1676, -0.2817,  0.1042],\n",
       "         [-0.2488,  0.1044, -0.1778,  ..., -0.2713, -0.2643,  0.2310],\n",
       "         [-0.0266, -0.0469,  0.0053,  ...,  0.0085,  0.0417, -0.0486]]]), tensor([[[-0.3443, -0.6315, -0.6647,  ...,  0.0050,  0.1167,  0.3614],\n",
       "         [ 0.8173, -0.9999, -0.1752,  ..., -0.4932, -0.2556,  0.2038],\n",
       "         [ 0.8973, -0.2652, -0.6559,  ...,  0.5725,  0.4178, -0.6356],\n",
       "         ...,\n",
       "         [ 1.5582,  0.4479, -1.2054,  ...,  0.2052, -0.5083,  0.3994],\n",
       "         [-0.1898,  0.0898, -0.2766,  ..., -0.3044, -0.4370,  0.4248],\n",
       "         [-0.0264, -0.0364,  0.0304,  ...,  0.0160,  0.0067, -0.0486]]]), tensor([[[-2.3737e-01, -9.9507e-01, -4.5364e-01,  ..., -2.1456e-01,\n",
       "           3.5440e-01,  2.5447e-01],\n",
       "         [ 5.7495e-01, -9.1262e-01, -2.3175e-01,  ..., -1.8444e-01,\n",
       "          -1.8389e-01,  1.3615e-01],\n",
       "         [ 2.5019e-01, -5.6334e-01, -7.0052e-01,  ...,  2.0830e-01,\n",
       "           6.6902e-01,  5.5973e-02],\n",
       "         ...,\n",
       "         [ 1.5415e+00,  3.5881e-03, -1.0563e+00,  ...,  6.0116e-02,\n",
       "          -3.6085e-01,  5.3854e-01],\n",
       "         [-5.8238e-01,  8.6807e-02, -4.4414e-01,  ..., -8.1630e-01,\n",
       "          -4.2633e-01,  4.1039e-01],\n",
       "         [ 1.3974e-02, -5.6850e-02, -4.0642e-03,  ...,  7.8790e-05,\n",
       "          -1.4510e-02, -4.7457e-02]]]), tensor([[[-1.5213e-01, -9.7455e-01, -5.6574e-01,  ..., -6.0023e-01,\n",
       "           3.0606e-01,  3.6930e-01],\n",
       "         [ 2.7012e-01, -5.4540e-01,  1.6653e-02,  ...,  6.2675e-02,\n",
       "           2.6824e-01,  3.4130e-02],\n",
       "         [-4.1255e-01, -6.4567e-01, -2.0088e-01,  ...,  2.3458e-01,\n",
       "           1.4713e-01,  4.0926e-03],\n",
       "         ...,\n",
       "         [ 1.3217e+00, -6.6626e-02, -8.1355e-01,  ..., -3.9645e-01,\n",
       "          -5.2719e-01,  2.0277e-01],\n",
       "         [-5.6073e-01, -4.5253e-01, -5.8201e-01,  ..., -1.4335e+00,\n",
       "           2.8755e-01,  5.9470e-01],\n",
       "         [ 6.2779e-05, -2.2453e-02, -2.1868e-02,  ..., -1.4897e-02,\n",
       "           2.8921e-03, -4.3436e-02]]]), tensor([[[ 0.0967, -0.8567, -0.5056,  ..., -0.4204,  0.1267,  0.3225],\n",
       "         [-0.0109, -0.2976,  0.2986,  ..., -0.3344,  0.2755, -0.1571],\n",
       "         [-0.6171, -0.4909, -0.1630,  ..., -0.3340,  0.4452, -0.2641],\n",
       "         ...,\n",
       "         [ 0.9738,  0.0119, -0.6562,  ..., -0.3114, -0.1033,  0.1980],\n",
       "         [-0.8265, -0.4334, -0.7586,  ..., -1.2721,  0.0482,  0.3751],\n",
       "         [ 0.0196,  0.0017,  0.0323,  ..., -0.0348, -0.0410, -0.0743]]]), tensor([[[-0.3495, -0.7788, -0.7701,  ..., -0.0715,  0.2350,  0.1686],\n",
       "         [-0.2694, -0.3884, -0.3181,  ..., -0.7334,  0.0196, -0.4148],\n",
       "         [-0.5444, -0.3546, -0.2131,  ..., -0.5306,  0.2799, -0.3587],\n",
       "         ...,\n",
       "         [ 0.6356,  0.0980, -0.2775,  ..., -0.6243, -0.2620,  0.1343],\n",
       "         [-0.4167,  0.1132, -0.4761,  ..., -0.5415, -0.1268,  0.0483],\n",
       "         [-0.0671, -0.0451,  0.0232,  ..., -0.0718, -0.0020, -0.0556]]]), tensor([[[-0.9560, -1.0372, -0.8875,  ...,  0.0905, -0.3867,  0.3258],\n",
       "         [-0.3215, -1.1213, -0.2349,  ..., -0.5940,  0.1851, -0.5076],\n",
       "         [-0.4795, -1.0745, -0.1744,  ..., -0.5026,  0.1293, -0.1963],\n",
       "         ...,\n",
       "         [ 0.2736, -0.4021, -0.1525,  ..., -0.7099, -0.7498, -0.0066],\n",
       "         [-0.0143,  0.0187, -0.0490,  ..., -0.0197, -0.0281,  0.0165],\n",
       "         [-0.5765, -0.5547, -0.2122,  ...,  0.2610, -0.4111, -0.1223]]]), tensor([[[-0.6121, -0.6371, -0.8917,  ...,  0.1026, -0.2241,  0.3330],\n",
       "         [-0.2817, -0.6142, -0.4499,  ..., -0.7273,  0.0304, -0.5106],\n",
       "         [-0.4519, -0.2628, -0.1917,  ..., -0.5405, -0.2146, -0.2140],\n",
       "         ...,\n",
       "         [ 0.3213, -0.2997, -0.0471,  ..., -0.8094, -0.7861, -0.0618],\n",
       "         [ 0.0430,  0.0219, -0.0214,  ...,  0.0196, -0.0353,  0.0072],\n",
       "         [-0.0599, -0.6397, -0.6008,  ...,  0.4218, -0.5170, -0.1616]]]), tensor([[[-0.4964, -0.1831, -0.5231,  ..., -0.1902,  0.3738,  0.3964],\n",
       "         [-0.1323, -0.2762, -0.3495,  ..., -0.4567,  0.3786, -0.1096],\n",
       "         [-0.3626, -0.4002,  0.0676,  ..., -0.3207, -0.2709, -0.3004],\n",
       "         ...,\n",
       "         [ 0.2961, -0.2856, -0.0382,  ..., -0.6056, -0.5163,  0.2005],\n",
       "         [ 0.4878, -0.0909, -0.2358,  ..., -0.0017, -0.5945, -0.2431],\n",
       "         [-0.2517, -0.3519, -0.4688,  ...,  0.2500,  0.0336, -0.2627]]])), past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we enabled output_hidden_states = True that's why we will get three outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand BERT Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first output = last_hidden_state with shape torch.Size([1, 22, 768])\n",
      "second output = pooler_output with shape torch.Size([1, 768])\n",
      "==================================================\n",
      "third output\n",
      "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
      "Number of batches: 1\n",
      "Number of tokens: 22\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print(f'first output = last_hidden_state with shape {outputs[0].shape}')\n",
    "print(f'second output = pooler_output with shape {outputs[1].shape}')\n",
    "print('='*50)\n",
    "print('third output')\n",
    "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert base has 12 bert layers and for each bert layer it gives embaddings for tokens. we are getting number of layers = 13 because the model adds one additional embadding layer at very beggining.\n",
    "Now lets understand the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"BertOutputs.png\" alt=\"huggingface\" style=\"width:800px;height:400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pooler Output : Creator of BERT model said that pooler_output which corresponds to last hidden state of [CLS] token does not have any interpretability but it is best choice as an input for a classifer that can be fine tuned on separate dataset. The main reason behind this is the way it pretrained. We must not forget that we are using BERT model as transfer learning which is already pretrained on large amount of data. [CLS] token is always used at starting token while performing pretraing using masked language model and next sentense prediction that's why pooler output which itself don't have any interpretability but it captures all the information for a perticular input.\n",
    "* Hidden_state : The second reason to love this model is its hidden state. BERT application is not limited to use pooler output to fine tune the classifier but one can also explore the advantages by using its hidden states. Though there is not hard and fast rule to which hidden state to use for embadding but depending on dataset and tasks one can try this followings combination\n",
    "\n",
    "<img src=\"hiddenembadding.png\" alt=\"huggingface\" style=\"width:800px;height:400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for cross check first output which is last hidden state and last index of third output which is all hidden_state should be same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4964, -0.1831, -0.5231,  ..., -0.1902,  0.3738,  0.3964],\n",
       "         [-0.1323, -0.2762, -0.3495,  ..., -0.4567,  0.3786, -0.1096],\n",
       "         [-0.3626, -0.4002,  0.0676,  ..., -0.3207, -0.2709, -0.3004],\n",
       "         ...,\n",
       "         [ 0.2961, -0.2856, -0.0382,  ..., -0.6056, -0.5163,  0.2005],\n",
       "         [ 0.4878, -0.0909, -0.2358,  ..., -0.0017, -0.5945, -0.2431],\n",
       "         [-0.2517, -0.3519, -0.4688,  ...,  0.2500,  0.0336, -0.2627]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4964, -0.1831, -0.5231,  ..., -0.1902,  0.3738,  0.3964],\n",
       "         [-0.1323, -0.2762, -0.3495,  ..., -0.4567,  0.3786, -0.1096],\n",
       "         [-0.3626, -0.4002,  0.0676,  ..., -0.3207, -0.2709, -0.3004],\n",
       "         ...,\n",
       "         [ 0.2961, -0.2856, -0.0382,  ..., -0.6056, -0.5163,  0.2005],\n",
       "         [ 0.4878, -0.0909, -0.2358,  ..., -0.0017, -0.5945, -0.2431],\n",
       "         [-0.2517, -0.3519, -0.4688,  ...,  0.2500,  0.0336, -0.2627]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[2][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word bank occures at index 6th , 10th and 19th. first we will see that embaddings are different or not and then we will examine whether it hold the contextual information or not by calculation cosin distance. Though the embadding vector is 768 dimentional but I will print first five just for comparision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token : bank , Embaddings : tensor([ 0.9001, -0.5380, -0.1669,  0.2242,  0.6897])\n",
      "token : bank , Embaddings : tensor([ 0.7977, -0.5217, -0.1984,  0.1890,  0.5941])\n",
      "token : bank , Embaddings : tensor([ 0.2961, -0.2856, -0.0382,  0.1674,  0.7713])\n"
     ]
    }
   ],
   "source": [
    "for i, token in enumerate(tokenized_text):\n",
    "    if token == 'bank':\n",
    "        print(f'token : {token} , Embaddings : {outputs[0][0][i][0:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity between 1st and 2nd bank 0.9527\n",
      "cosine similarity between 1st and 3rd bank 0.6989\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "similarity12 = 1 - cosine(outputs[0][0][6],outputs[0][0][10])\n",
    "print(f'cosine similarity between 1st and 2nd bank {similarity12:.4f}')\n",
    "\n",
    "similarity13 = 1 - cosine(outputs[0][0][6],outputs[0][0][19])\n",
    "print(f'cosine similarity between 1st and 3rd bank {similarity13:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that BERT generates different embaddings for same word 'bank' and also holds the contextual information as cosine similarity between first and second bank is high where it is low for first and third bank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till now we have understand BERT tokens , token ids , BERT Embaddings and model outputs including last hidden output , pooled output and hidden states and we also seen that BERT Embadding takes care of contextual information.\n",
    "\n",
    "Now let's start our main task which is QnA. First we will load the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer in BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this blog I will talk about sections in Embadding layer and not the bert layer as I am assuming that reader already know about self attention , attention heads , query , key , value , layer_norm and finaly feed forward output layer.\n",
    "word_embaddings : At the beggining there is a section in embadding layer called word_embedding which has a matrix of size (30522,1024). This matrix can be thought of as a dictionary where keys are token ids and values are 1024(bert-large) dimentional vector. Note that this matrix is trainable and model will update vectors (by back propagation ) corresponding to only those tokens which are present in the traing data while fine tuning the model. \n",
    "\n",
    "Remember that this embadding matrix is just a dictionary which gives same vectors for same token, it is last hidden layer output where we can expect different embadding for same word that captures context information.\n",
    "\n",
    "position_embeddings : BERT-base and BERT-large both can accept sentence whose token lengths is less than 512. \n",
    "so before feeding inputs to the model ensure that the length of tokens should be less than or equal to 512. Unlike LSTM or RNN we feed entire sequence to the model in one go so the model has to do something to understand the sequence information(which word come before and which come after). Model adds possitional embedding to each tokens to do so. I think that positional matrix is not trainable because it is used just to tell model that which word comes before and which comes later and they did lots of research to come up with this matrix.\n",
    "\n",
    "\n",
    "token_type_embeddings: Remember that bert model is pretrained on large datset using masked language model and next sentence prediction. So by default model expect two sentences as input which are separated by [SEP] token though task like classification and sentiment analysis do not feed two sentences as input. In task like classification we feed additional attention mask that tells model that which token is coming from sentences and which are just padding tokens to match the length. In task like QnA where we have to feed two sentences first as passage and second for que so we must provide additional segment ids (0's for first segment and 1's for second segmnet). we will see this in detail when we pass a input to our QnA model.\n",
    "\n",
    "So what is this token_type_embeddings (2,1024)? \n",
    "we feed additional segment ids but the token embaddings are 1024 dimentional vector. I think that token_type_embeddings provides 1024 dimentional zero vector for segment id ==0 and 1024 dimentional vector with ones for segment id = 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before talking about last linear layer let's take our first eg. to test the model BERT-large-for-Que-Ans.\n",
    "BertTokenizer provides inbuilt module called 'encode' that takes pair of question and passage sentense and perform three task.\n",
    "first it performs tokenization to get the tokens from vocabulary for entire input.\n",
    "then it places [CLS] token at the start and [SEP] token at the end of first sequence and after the end of last sequence.\n",
    "then it gives token ids for all the tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT for QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input has a total of 106 tokens.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "question = \"Which mechnism that BERT use?\"\n",
    "\n",
    "answer_text = ''' BERT makes use of Transformer, an attention mechanism that learns contextual relations between \n",
    "        words (or sub-words) in a text. In its vanilla form, Transformer includes two separate \n",
    "        mechanisms — an encoder  that reads the text input and a decoder that produces a prediction \n",
    "        for the task. Since BERT’s goal is to generate a language model, only the encoder mechanism \n",
    "        is necessary. The detailed workings of Transformer are described in a paper by Google.'''\n",
    "\n",
    "# Apply the tokenizer to the input text, treating them as a text-pair.\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "input_ids = tokenizer.encode(question, answer_text)\n",
    "print('The input has a total of {:} tokens.'.format(len(input_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of code can be used to visualize token and its corresponding ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "which         2,029\n",
      "me            2,033\n",
      "##ch          2,818\n",
      "##nism       28,113\n",
      "that          2,008\n",
      "bert         14,324\n",
      "use           2,224\n",
      "?             1,029\n",
      "\n",
      "[SEP]           102\n",
      "\n",
      "bert         14,324\n",
      "makes         3,084\n",
      "use           2,224\n",
      "of            1,997\n",
      "transform    10,938\n",
      "##er          2,121\n",
      ",             1,010\n",
      "an            2,019\n",
      "attention     3,086\n",
      "mechanism     7,337\n",
      "that          2,008\n",
      "learns       10,229\n",
      "context       6,123\n",
      "##ual         8,787\n",
      "relations     4,262\n",
      "between       2,090\n",
      "words         2,616\n",
      "(             1,006\n",
      "or            2,030\n",
      "sub           4,942\n",
      "-             1,011\n",
      "words         2,616\n",
      ")             1,007\n",
      "in            1,999\n",
      "a             1,037\n",
      "text          3,793\n",
      ".             1,012\n",
      "in            1,999\n",
      "its           2,049\n",
      "vanilla      21,161\n",
      "form          2,433\n",
      ",             1,010\n",
      "transform    10,938\n",
      "##er          2,121\n",
      "includes      2,950\n",
      "two           2,048\n",
      "separate      3,584\n",
      "mechanisms   10,595\n",
      "—             1,517\n",
      "an            2,019\n",
      "en            4,372\n",
      "##code       16,044\n",
      "##r           2,099\n",
      "that          2,008\n",
      "reads         9,631\n",
      "the           1,996\n",
      "text          3,793\n",
      "input         7,953\n",
      "and           1,998\n",
      "a             1,037\n",
      "deco         21,933\n",
      "##der         4,063\n",
      "that          2,008\n",
      "produces      7,137\n",
      "a             1,037\n",
      "prediction   17,547\n",
      "for           2,005\n",
      "the           1,996\n",
      "task          4,708\n",
      ".             1,012\n",
      "since         2,144\n",
      "bert         14,324\n",
      "’             1,521\n",
      "s             1,055\n",
      "goal          3,125\n",
      "is            2,003\n",
      "to            2,000\n",
      "generate      9,699\n",
      "a             1,037\n",
      "language      2,653\n",
      "model         2,944\n",
      ",             1,010\n",
      "only          2,069\n",
      "the           1,996\n",
      "en            4,372\n",
      "##code       16,044\n",
      "##r           2,099\n",
      "mechanism     7,337\n",
      "is            2,003\n",
      "necessary     4,072\n",
      ".             1,012\n",
      "the           1,996\n",
      "detailed      6,851\n",
      "workings     24,884\n",
      "of            1,997\n",
      "transform    10,938\n",
      "##er          2,121\n",
      "are           2,024\n",
      "described     2,649\n",
      "in            1,999\n",
      "a             1,037\n",
      "paper         3,259\n",
      "by            2,011\n",
      "google        8,224\n",
      ".             1,012\n",
      "\n",
      "[SEP]           102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenizer's behavior, let's also get the token strings and display them.\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "# For each token and its id...\n",
    "for token, id in zip(tokens, input_ids):\n",
    "    \n",
    "    # If this is the [SEP] token, add some space around it to make it stand out.\n",
    "    if id == tokenizer.sep_token_id:\n",
    "        print('')\n",
    "    \n",
    "    # Print the token string and its ID in two columns.\n",
    "    print('{:<12} {:>6,}'.format(token, id))\n",
    "\n",
    "    if id == tokenizer.sep_token_id:\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Now we have to generate segment ids to tell the model that which token id belongs to first sequence and which token id belongs to second sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Search the input_ids for the first instance of the `[SEP]` token.\n",
    "sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "# The number of segment A tokens includes the [SEP] token istelf.\n",
    "num_seg_a = sep_index + 1\n",
    "\n",
    "# The remainder are segment B.\n",
    "num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "# Construct the list of 0s and 1s.\n",
    "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "# There should be a segment_id for every input token.\n",
    "assert len(segment_ids) == len(input_ids)\n",
    "print(segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(segment_ids) == len(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have processed our input (question and passage) into the form that our BERT model expects the input to be. Let's convert processed input into tensor in feed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-5.9297, -8.2512, -8.2334, -9.1164, -7.8028, -7.8494, -8.5925, -8.2909,\n",
       "         -9.3075, -5.9297,  0.9577, -3.3898, -4.1839, -4.8172,  6.8211, -1.1268,\n",
       "         -4.5010,  1.2108,  0.5921, -2.3455, -5.4775, -3.0783, -4.2873, -7.1977,\n",
       "         -5.5380, -6.3641, -5.0001, -7.8545, -7.7550, -5.7282, -8.6403, -6.3636,\n",
       "         -7.2707, -7.0612, -6.2764, -3.3167, -5.9297, -4.0268, -4.3900, -1.6861,\n",
       "         -5.1395, -6.9378,  3.0385, -4.0382, -5.7145, -3.7573, -6.3599, -5.2701,\n",
       "         -7.0734, -2.5215, -1.6866, -5.7555, -5.9852, -7.0097, -5.1551, -7.8404,\n",
       "         -5.6063, -6.1879, -7.9365, -4.8895, -2.9879, -6.2326, -7.8125, -6.4680,\n",
       "         -7.9348, -5.5899, -8.5970, -8.7157, -6.4139, -6.9194, -5.1876, -4.0657,\n",
       "         -8.0904, -8.7001, -5.9679, -8.7346, -6.2633, -4.2040, -5.9619, -3.7574,\n",
       "         -5.8462, -8.6115, -4.1992, -4.1589, -2.2915, -6.3091, -6.5090, -6.5777,\n",
       "         -8.5397, -6.8958, -8.5823, -7.2457, -6.5215, -6.4697, -6.0551,  2.6920,\n",
       "         -4.6026, -8.1929, -7.0744, -8.2434, -7.3349, -6.8112, -8.0685, -4.2300,\n",
       "         -8.9940, -5.9298]], grad_fn=<SqueezeBackward1>), end_logits=tensor([[-2.0457, -6.4955, -7.9466, -7.4553, -6.3083, -7.1423, -7.7016, -7.5700,\n",
       "         -7.6180, -2.0457, -3.2929, -5.4357, -4.1795, -3.9602, -0.4123,  7.6697,\n",
       "          2.5434, -4.2775, -0.8734,  1.6306, -5.8033, -4.7115, -5.4883, -5.0109,\n",
       "         -2.7099, -5.2240, -1.4783, -6.1123, -7.3203, -6.0510, -7.0553, -2.4202,\n",
       "         -1.3796, -5.6966, -5.9495,  0.3820, -2.0456, -7.3530, -5.9187, -0.9416,\n",
       "         -1.5484, -4.1270, -3.0279,  3.3656, -5.8839, -4.9630, -5.7683, -2.0026,\n",
       "         -5.7780, -6.5706, -5.1330, -5.6540, -0.9588, -6.9344, -5.4972, -7.3136,\n",
       "         -4.1291, -2.5613, -6.2907, -6.7217, -5.2990, -0.7752, -6.5759, -6.0620,\n",
       "         -6.6111, -2.7530, -6.7255, -6.4059, -1.3597, -2.1516, -7.4117, -6.0066,\n",
       "         -6.2648, -6.9635, -6.8059, -7.7292, -7.8618, -5.7763, -7.3990, -4.0310,\n",
       "         -1.9292, -5.4911, -6.9799, -6.9642, -5.1570, -5.9594, -1.5521, -2.8265,\n",
       "         -7.6460, -3.3834, -3.8124, -7.2804, -7.6054, -5.8695, -6.8296, -3.3571,\n",
       "          3.0043, -7.3120, -6.9330, -7.6553, -7.5059, -6.0044, -7.6986, -2.9624,\n",
       "         -5.0966, -2.0460]], grad_fn=<SqueezeBackward1>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run our example through the model.\n",
    "import torch\n",
    "outputs = model(\n",
    "            torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "            token_type_ids=torch.tensor([segment_ids]),# The segment IDs to differentiate question from answer_text\n",
    "            return_dict=True\n",
    "                ) \n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 106]) torch.Size([1, 106])\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0].shape , outputs[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output is list of two tensor each of those is 106 dimentional vector. To understand this output now let's talk about last linear layer of our model.\n",
    "\n",
    "(take screenshot of last linear layer)(img)\n",
    "\n",
    "The last linear layer takes input as 1024 dimentional vector and generate two outputs. After carefully reading this [code](https://huggingface.co/transformers/_modules/transformers/models/bert/modeling_bert.html#BertForQuestionAnswering)  provided by huggingface library I got to know that this last linear layer takes input from last hidden state of every input tokens and for each input token this last linear layer generates two outputs. The value of \n",
    "first output indicate the chance of corresponding token to be the start index of the final answer. Large positive value means high chance that corresponding token is the starting index and large negative means low chance to be the starting index of the final answer. Same idea applicable for second output except it is related to end index of the final answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this everything is very simple, you just have to find the index of largest value in the first output and assign its corresponding token as starting index  and same for second output to get the last index of the final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \"transform ##er\"\n"
     ]
    }
   ],
   "source": [
    "start_scores = outputs.start_logits\n",
    "end_scores = outputs.end_logits\n",
    "\n",
    "answer_start = torch.argmax(start_scores)\n",
    "answer_end = torch.argmax(end_scores)\n",
    "\n",
    "# Combine the tokens in the answer and print it out.\n",
    "answer = ' '.join(tokens[answer_start:answer_end+1])\n",
    "\n",
    "print('Answer: \"' + answer + '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of indexing of outputs we can also use start_logits (index 0) and end_logits (index 1). We can remove this # tags and combine the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question : Which mechnism that BERT use?\n",
      "Expected Answer : transformer as attention\n",
      "Predicted Answer : transformer\n"
     ]
    }
   ],
   "source": [
    "answer = answer.replace(' ##','')\n",
    "print('Question : Which mechnism that BERT use?')\n",
    "print('Expected Answer : transformer as attention')\n",
    "print(f'Predicted Answer : {answer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you must be appreciating the brilliant idea of creator of this BERT model that how geniously they uses the idea of attention mechnism because by adding one more linear layer only the model is able to predict starting token and ending token of the final answer based on perticular question that means the model very well understands the meaning of a question and able to find the answer in given passage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example provided by huggingface for que and ans didn't explian about the situation where start index > end index. In my case I didn't get those situation but if it occures then I think that instead of largest value index we can use 2nd largest value index depending on situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets make helper function that takes question ans passage as input and will return final answer and test the model for other questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def get_ans(que,passage):\n",
    "    \n",
    "    input_ids = tokenizer.encode(que, passage)\n",
    "    \n",
    "    # tokenizer's behavior, let's also get the token strings and display them.\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
    "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    # The number of segment A tokens includes the [SEP] token istelf.\n",
    "    num_seg_a = sep_index + 1\n",
    "\n",
    "    # The remainder are segment B.\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "    # Construct the list of 0s and 1s.\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "    \n",
    "    outputs = model(\n",
    "            torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "            token_type_ids=torch.tensor([segment_ids]),# The segment IDs to differentiate question from answer_text\n",
    "            return_dict=True\n",
    "                )\n",
    "    start_scores = outputs.start_logits\n",
    "    end_scores = outputs.end_logits\n",
    "\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "   \n",
    "    # Combine the tokens in the answer and print it out.\n",
    "    answer = ' '.join(tokens[answer_start:answer_end+1])\n",
    "    answer = answer.replace(' ##','')\n",
    "    return answer\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Answer : deep learning\n",
      "Predicted Answer : deep learning\n"
     ]
    }
   ],
   "source": [
    "passage = 'Computer vision is evolving rapidly day-by-day. Its one of the reason is deep learning.\\\n",
    "           When we talk about computer vision, a term convolutional neural network( abbreviated as CNN)\\\n",
    "           comes in our mind because CNN is heavily used here. Examples of CNN in computer vision are \\\n",
    "           face recognition,image classification etc. It is similar to the basic neural network. CNN \\\n",
    "           also have learnable parameter like neural network i.e, weights, biases etc.'\n",
    "\n",
    "question = 'what is the reason behind evolution of Computer vision'\n",
    "\n",
    "answer = get_ans(question,passage)\n",
    "print('Expected Answer : deep learning')\n",
    "print(f'Predicted Answer : {answer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Answer : convolutional neural network\n",
      "Predicted Answer : convolutional neural network\n"
     ]
    }
   ],
   "source": [
    "question = 'what is abbriviated as CNN'\n",
    "answer = get_ans(question,passage)\n",
    "print('Expected Answer : convolutional neural network')\n",
    "print(f'Predicted Answer : {answer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Answer : face recognition , image classification\n"
     ]
    }
   ],
   "source": [
    "question = 'what are the application of CNN'\n",
    "answer = get_ans(question,passage)\n",
    "print(f'Predicted Answer : {answer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer vision is evolving rapidly day-by-day. Its one of the reason is deep learning. When we talk about computer vision, a term convolutional neural network( abbreviated as CNN) comes in our mind because CNN is heavily used here. Examples of CNN in computer vision are face recognition, image classification etc. It is similar to the basic neural network. CNN also have learnable parameter like neural network i.e, weights, biases etc.\n"
     ]
    }
   ],
   "source": [
    "print(passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
